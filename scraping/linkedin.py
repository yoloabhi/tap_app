# -*- coding: utf-8 -*-
"""linkedin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12esoN1PIv5ecB_nYHCMaWqy7se4dgaud
"""

!pip install selenium
!apt-get update # to update ubuntu to correctly run apt install
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin
import sys
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')
from selenium import webdriver
chrome_options = webdriver.ChromeOptions()
# chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
# wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
# wd.get("https://www.webite-url.com")

import requests,time,random
from bs4 import BeautifulSoup
from selenium import webdriver

chrome_options = webdriver.ChromeOptions()
# chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
browser = webdriver.Chrome(executable_path=r"chromedriver",chrome_options=chrome_options)
browser.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')
username=input()
password=input()
elementID= browser.find_element_by_id('username')
elementID.send_keys(username)
elementID= browser.find_element_by_id('password')
elementID.send_keys(password)
elementID.submit()

link = 'https://www.linkedin.com/in/ishan-kumar-7076a0179/'
browser.get(link)

SCROLL_PAUSE_TIME =5

last_height=browser.execute_script("return document.body.scrollHeight")

for i in  range(3):
    browser.execute_script("window.scrollTo(0,document.body.scrollHeight);")
    time.sleep(SCROLL_PAUSE_TIME)
    new_height=  browser.execute_script("return document.body.scrollHeight")
    if new_height==last_height:
        break
    last_height=new_height

src = browser.page_source
soup = BeautifulSoup(src, 'lxml')
name_div = soup.find('div', {'class': 'pv-text-details__left-panel mr5'})
name_div

name = soup.find('h1', {'class': 'text-heading-xlarge inline t-24 v-align-middle break-words'}).get_text()
name

organisation= soup.find('div', {'class': 'inline-show-more-text inline-show-more-text--is-collapsed inline-show-more-text--is-collapsed-with-line-clamp'}).get_text().strip()
organisation

location= soup.find('span', {'class': 'text-body-small inline t-black--light break-words'}).get_text().strip()
location

exper=[]
exp=soup.find('section',{'id':'experience-section'})
exp_ul=exp.find('ul')
exp_li=exp_ul.find_all('li')
for i in exp_li:
    exp_a=i.find('a')
    job=[]
    title=exp_a.find('h3').get_text()
    job.append(title)
    company=exp_a.find('p').get_text()
    job.append(company)
    dur=exp_a.find_all('span')[2]
#     for j in dur:
#         if j.has_attr('class'):
    print(dur)

info = []
info.append(link)
info.append(name)
info.append(organisation)
info.append(location)
info

